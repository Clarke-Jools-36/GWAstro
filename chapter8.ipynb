{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v8uAsnkIClQ"
      },
      "source": [
        "# Chapter 8 - Detector Networks and CBCs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d72CBNOHIClc"
      },
      "source": [
        "## Imports\n",
        "\n",
        "We will need some standard imports for this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VmTaKb_AIClc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L2PwRD4ICld"
      },
      "source": [
        "And we will need the GW-specific software `gwpy` and `pycbc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3rxM_oK8ICle",
        "outputId": "29b2ddaf-c7a6-4103-caf6-81022ea101b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ligo-segments (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -q gwpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OKjL-AcZICle",
        "outputId": "54375471-a1e1-4799-b4aa-aeb33b914742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.2/201.2 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.9/297.9 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lscsoft-glue (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pegasus-wms.api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-ligo-lw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pegasus-wms.common (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -q lalsuite pycbc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0dU7NFiICle"
      },
      "source": [
        "## Data\n",
        "\n",
        "As a concrete example we will continue working with the data containing **GW150914**.  Since we know *a priori* that there isn't any signal content about 1 kHz, we'll downsample the data to 2048 Hz for faster processing.  Now we will use both Hanford and Livingston data.\n",
        "\n",
        "_Note:_ we are using [dictionaries](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) instead of [lists](https://docs.python.org/3/tutorial/introduction.html#lists) here. You can think those as similar to lists, but indexed with specific names instead of numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RG9RTFLdICle"
      },
      "outputs": [],
      "source": [
        "from gwpy.timeseries import TimeSeries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X5JcwMthIClf",
        "outputId": "88a96851-1e34-41b8-d483-f9a4cded13a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwosc/api.py\u001b[0m in \u001b[0;36mfetch_json\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mJSON_CACHE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'https://www.gw-openscience.org/eventapi/jsonfull/allevents/'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f75c7e34640>: Failed to establish a new connection: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.gw-openscience.org', port=443): Max retries exceeded with url: /eventapi/jsonfull/allevents/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f75c7e34640>: Failed to establish a new connection: [Errno 110] Connection timed out'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-62e331b523b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mifos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'H1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# a list which we use as the dictionary keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mifo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mifos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mifo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_open_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_center\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_center\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwpy/timeseries/core.py\u001b[0m in \u001b[0;36mfetch_open_data\u001b[0;34m(cls, ifo, start, end, sample_rate, tag, version, format, host, verbose, cache, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_gwosc_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         return fetch_gwosc_data(\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0mifo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwpy/timeseries/io/losc.py\u001b[0m in \u001b[0;36mfetch_gwosc_data\u001b[0;34m(detector, start, end, cls, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'sample_rate'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_kw\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# format as Hertz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0murl_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_rate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murl_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;31m# if event dataset, pick shortest file that covers the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# -- this is a bit hacky, and presumes that only an event dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwosc/locate.py\u001b[0m in \u001b[0;36mget_urls\u001b[0;34m(detector, start, end, dataset, tag, version, sample_rate, format, host)\u001b[0m\n\u001b[1;32m    114\u001b[0m         )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# get URL list for this dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdstype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"run\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwosc/datasets.py\u001b[0m in \u001b[0;36m_iter_datasets\u001b[0;34m(detector, type, segment, catalog, version, match, host)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mneedthis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_yield_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwosc/datasets.py\u001b[0m in \u001b[0;36m_yield_matches\u001b[0;34m(iter_)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_yield_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwosc/datasets.py\u001b[0m in \u001b[0;36m_event_datasets\u001b[0;34m(detector, segment, catalog, version, host)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mfull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msegment\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     for dset, meta in api.fetch_allevents_json(\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwosc/api.py\u001b[0m in \u001b[0;36mfetch_allevents_json\u001b[0;34m(full, host)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_jsonfull_allevents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetch_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_allevents_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetch_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_allevents_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gwosc/api.py\u001b[0m in \u001b[0;36mfetch_json\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fetching {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             return JSON_CACHE.setdefault(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.gw-openscience.org', port=443): Max retries exceeded with url: /eventapi/jsonfull/allevents/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f75c7e34640>: Failed to establish a new connection: [Errno 110] Connection timed out'))"
          ]
        }
      ],
      "source": [
        "time_center = 1126259462\n",
        "\n",
        "data={} # an empty dictionary\n",
        "ifos=['L1','H1'] # a list which we use as the dictionary keys\n",
        "for ifo in ifos:\n",
        "    data[ifo] = TimeSeries.fetch_open_data(ifo, time_center - 16, time_center + 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ath9xrTaIClf"
      },
      "outputs": [],
      "source": [
        "# Remove the low frequency content and downsample the data to 2048Hz\n",
        "for ifo in ['H1','L1']:\n",
        "    data[ifo] = data[ifo].highpass(15).resample(2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLbAPciuIClg"
      },
      "source": [
        "Taking a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs_4igGNIClg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "colours=['gwpy:ligo-livingston','gwpy:ligo-hanford']\n",
        "\n",
        "for ifo,colour in zip(ifos,colours):\n",
        "    plt.plot(data[ifo],label='{} data'.format(ifo),color=colour)\n",
        "plt.xlabel('GPS Time [s]')\n",
        "plt.ylabel('Strain')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIKM2CumICli"
      },
      "source": [
        "## Likelihood\n",
        "\n",
        "### Noise model\n",
        "\n",
        "We know the time around **GW150914** to be well-behaved, and by that we mean stationary and Gaussian.  That means we can completely describe the (statistical) properties of the noise by the power spectral density, which we'll estimate using off-source data following the procedure in `chapter5_6.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9skKbkYlIClj"
      },
      "outputs": [],
      "source": [
        "psd={}\n",
        "for ifo in ifos:\n",
        "    psd[ifo] = data[ifo].psd(fftlength=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLaPU90HIClj"
      },
      "outputs": [],
      "source": [
        "for ifo,colour in zip(ifos,colours):\n",
        "    plt.loglog(psd[ifo],label='{} PSD'.format(ifo),color=colour)\n",
        "\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.ylabel('Strain noise [$1/\\mathrm{Hz}$]')\n",
        "plt.xlim(20,1024)\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyKDwXelIClj"
      },
      "source": [
        "That's it.  We're going to assume that our noise is exactly described by the PSD estimated above.  In other words, we're employing a 0-parameter noise model.\n",
        "\n",
        "For production analyses we make use of the [BayesLine](https://arxiv.org/abs/1410.3852) algorithm, which employs a parametric model for the PSD itself and allows us to work with only on-source data.\n",
        "\n",
        "## Signal model\n",
        "\n",
        "Here we are using the `SEOBNRv4` approximant, which describes the inspiral, merger, and ringdown phases of a binary black hole merger using a combination of analytical approximations and fits to numerical relativity simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iFO3yiwIClk"
      },
      "outputs": [],
      "source": [
        "from pycbc.waveform import get_td_waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ul5kG1YIClk"
      },
      "outputs": [],
      "source": [
        "m1 = 38.9 # Solar masses\n",
        "m2 = 31.6 # Solar masses\n",
        "\n",
        "hp, hc = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
        "                     mass1=m1,\n",
        "                     mass2=m2,\n",
        "                     delta_t=data['H1'].dt.value,\n",
        "                     f_lower=20)\n",
        "\n",
        "plt.plot(hp.sample_times, hp)\n",
        "plt.xlabel('Time (s)');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJlUA_lIClm"
      },
      "source": [
        "With two detectors we are potentially sensitive to more than a single polarization of gravitational waves.  We also have to account for the delay in the time of arrival of the signal based on where in the sky the source may be located.  This expands our parameters to be component mass (assuming an equal mass binary), right ascension, declination, luminosity distance, inclination, merger time, merger phase, and polarization angle.\n",
        "\n",
        "For a give set of parameters $\\vec{\\lambda}$ we'll now have to generate the plus and cross polarizations of the GW emission (taking into account the inclination of the binary, and scaling to the proper distance), then combine these with each detector's antenna pattern (which depend on the location of the binary relative to the detector's orientation) to determine the detector response.  Finally, we have to shift the time of arrival of the signal to be consistent with the delay time expected based on the RA and dec of the binary.\n",
        "\n",
        "In short, you can think of the process as generating the geocenter waveform then projecting it across the network.\n",
        "\n",
        "Here we will use the `Detector` python object with which we can compute the antenna beam patterns $F_+$ and $F_{\\times}$ for a a specific sky-position and polarisation angle:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y03xHgkpICln"
      },
      "outputs": [],
      "source": [
        "from pycbc.detector import Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dInPSnNjIClo"
      },
      "outputs": [],
      "source": [
        "# Creating the detector objects:\n",
        "det={}\n",
        "for ifo in ifos:\n",
        "    det[ifo]=Detector(ifo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2itg9Ue6IClo"
      },
      "outputs": [],
      "source": [
        "declination = 2.2\n",
        "right_ascension =  -1.2\n",
        "polarization = 0.0\n",
        "\n",
        "fp={}\n",
        "fc={}\n",
        "for ifo in ifos:\n",
        "    fp[ifo], fc[ifo] = det[ifo].antenna_pattern(right_ascension, declination, polarization, time_center)\n",
        "    print(\"{}: fp={}, fc={}\".format(ifo,fp[ifo], fc[ifo]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWaHg2cNIClo"
      },
      "source": [
        "# **Question**\n",
        "- make a 2D plot (right-ascension and declination) of the $F_+$ (`fp`) and $F_{\\times}$ (`fc`) functions for a detector at a fixed polarisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye9Hk3fqIClp"
      },
      "source": [
        "With the antenna beam pattern functions we can then compute the gravitational-wave signal as seen by each detector:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUPPZV3WIClp"
      },
      "outputs": [],
      "source": [
        "ht={}\n",
        "for ifo in ifos:\n",
        "    ht[ifo] = fp[ifo] * hp + fc[ifo] * hc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bm1oYM6nIClp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "for ifo,colour in zip(ifos,colours):\n",
        "    plt.plot(TimeSeries.from_pycbc(ht[ifo]),label='{} signal'.format(ifo),color=colour)\n",
        "plt.xlabel('GPS Time [s]')\n",
        "plt.ylabel('Strain')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzk37BKTIClq"
      },
      "source": [
        "For visualization it is still useful to look at the whitened data, where the data have been filtered to produce a flat PSD. We also remove the frequencies below 30Hz and above 300Hz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McF-DCpzIClq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "white_data={}\n",
        "for ifo,colour in zip(ifos,colours):\n",
        "    white_data[ifo]=data[ifo].whiten(fftlength=4).bandpass(30,300)\n",
        "    plt.plot(white_data[ifo],label='{} whitened data'.format(ifo),color=colour)\n",
        "plt.xlim(time_center+.2, time_center+.5)\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN_6VlXhIClq"
      },
      "source": [
        "# **Question**\n",
        "- the L1 detector is anti-aligned to the H1 detector (by construction). So it is possible to compare both strain data by multiplying one of them by -1. In addition, a time-delay needs to be taken into account to have both whitened data match well. Try to find by eye what that time-delay should be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N23fS5c3IClq"
      },
      "source": [
        "We also need to compute the time-delay between our refence time-at-geocenter and the time at which the gravitational-wave signal will hit the detectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cTjXwHRIClr"
      },
      "outputs": [],
      "source": [
        "time_delay=det['H1'].time_delay_from_earth_center(right_ascension, declination, time_center)\n",
        "\n",
        "print(\"For the sky-position ra={},dec={}, at time={},\".format(right_ascension,declination,time_center))\n",
        "print(\"the time delay between Hanford and geocenter is {} seconds\".format(time_delay))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN6orb_oIClr"
      },
      "source": [
        "# **Question**\n",
        "- Draw random ra,dec points in the sky, and plot the histogram of the time-delays. Why is it flat?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63GdIZ_PIClr"
      },
      "source": [
        "As in chapter 7, we'll make a light-weight wrapper for `get_td_waveform()` that will take parameter vector $\\vec{\\lambda}$ and generate a waveform for us with the same sampling rate and time window as our data. However, this time we need to project the \"plus\" and \"cross\" polarisations onto the detector arms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJPoYl2iIClr"
      },
      "outputs": [],
      "source": [
        "for ifo in ifos:\n",
        "    data[ifo]=data[ifo].crop(time_center-2,time_center+2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bogm3cv1ICls"
      },
      "outputs": [],
      "source": [
        "def gen_template(param,\n",
        "                 delta_t=data['H1'].dt.value, # Assuming all IFOs have the same dt !\n",
        "                 duration=data['H1'].duration.value, # Assuming all IFOs have the same duration !\n",
        "                 start_time=data['H1'].x0.value,# Assuming all IFOs have the same start time !\n",
        "                 f_lower=20.):\n",
        "    \n",
        "    m1, m2, distance, time, phase, right_ascension, declination, inclination, polarization = param\n",
        "\n",
        "    hp, hc = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
        "                             mass1=m1,\n",
        "                             mass2=m2,\n",
        "                             distance=distance,\n",
        "                             inclination=inclination,\n",
        "                             coa_phase=phase,\n",
        "                             delta_t=delta_t,\n",
        "                             f_lower=f_lower) \n",
        "    \n",
        "    # Resize the signal buffer\n",
        "    hp.resize(int(duration/delta_t))\n",
        "    hc.resize(int(duration/delta_t))\n",
        "    \n",
        "    ht={}\n",
        "    template={}\n",
        "    # compute the detectors responses and shift to the requested time\n",
        "    for ifo in ifos:\n",
        "        fp, fc = det[ifo].antenna_pattern(right_ascension, declination, polarization, time)\n",
        "        ht[ifo] = fp * hp.copy() + fc * hc.copy()\n",
        "        \n",
        "        time_delay = det[ifo].time_delay_from_earth_center(right_ascension, declination, time)\n",
        "        \n",
        "        ht[ifo] = ht[ifo].cyclic_time_shift(ht[ifo].start_time + time - start_time + time_delay)\n",
        "        ht[ifo].start_time=start_time\n",
        "    \n",
        "        template[ifo]=TimeSeries.from_pycbc(ht[ifo])\n",
        "\n",
        "    return template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQQjTuCCICls"
      },
      "outputs": [],
      "source": [
        "# Testing the gen_template() function:\n",
        "\n",
        "param=[38.9,31.6,410,1126259462.42,0.0,2.2, -1.2, 0.1, 0.]\n",
        "# m1, m2, distance, time, phase, right_ascension, declination, inclination, polarization = param\n",
        "\n",
        "template=gen_template(param)\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "for ifo,colour in zip(ifos,colours):\n",
        "    plt.plot(template[ifo],label='{} signal'.format(ifo),color=colour)\n",
        "plt.xlabel('GPS Time [s]')\n",
        "plt.ylabel('Strain')\n",
        "plt.legend();\n",
        "plt.axvline(time_center,c='forestgreen')\n",
        "plt.xlim([time_center-0.1,time_center+0.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiMOe1dJICls"
      },
      "source": [
        "With the network waveform generator now defined, we can define our likelihood function, which is equivalent to the product of single-detector likelihood functions.\n",
        "\n",
        "## Network Likelihood\n",
        "\n",
        "In chapter 7 we've only worked with one detector, and our inference abilities have been restricted by this.\n",
        "\n",
        "To construct a likelihood function for the GW detector network (the two LIGO instruments in this case), we will make the very reasonable assumption that noise is independent between detectors.  This means that our network likelihood fuction is just the product of single-detector likelihood functions.\n",
        "\n",
        "$$\n",
        "\\log \\mathcal{L}_\\mathrm{net} = \\sum_{j \\in \\{\\mathrm{H1}, \\mathrm{L1}\\}} \\log \\mathcal{L}_\\mathrm{j}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaP7AfnnIClt"
      },
      "outputs": [],
      "source": [
        "# FFT the data once, ahead of time\n",
        "sf={}\n",
        "for ifo in ifos:\n",
        "    sf[ifo] = data[ifo].average_fft(window=('tukey',1./4.))*data[ifo].duration.value/2\n",
        "\n",
        "def loglikelihood(param, sf=sf, f_lower=20.0):\n",
        "\n",
        "    logl=0.0    \n",
        "    template = gen_template(param, delta_t=data['H1'].dt.value ,f_lower=f_lower)\n",
        "    \n",
        "    for ifo in ifos:\n",
        "        # zero out the frequencies below f_lower\n",
        "        sf_hp = sf[ifo].crop(start=f_lower)\n",
        "        psd_hp = psd[ifo].crop(start=f_lower)\n",
        "        \n",
        "        hf = template[ifo].average_fft(window=('tukey',1./4.))*template[ifo].duration.value/2\n",
        "        hf_hp = hf.crop(start=f_lower)\n",
        "\n",
        "        h_dot_h  = 4 * np.real((hf_hp * hf_hp.conjugate() / psd_hp).sum() * hf_hp.df)\n",
        "        h_dot_s  = 4 * np.real((sf_hp * hf_hp.conjugate() / psd_hp).sum() * sf_hp.df)\n",
        "\n",
        "        logl += h_dot_s - h_dot_h/2\n",
        "\n",
        "    return logl.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLysNc9QIClt"
      },
      "source": [
        "Now let's pick some particular values for the model parameters that we know to be in the right ballpark and generate a model signal.  We'll then whiten it and compare it to the data, and calculate the likelihood."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO1EwEpFIClt"
      },
      "outputs": [],
      "source": [
        "# m1, m2, distance, time, phase, right_ascension, declination, inclination, polarization\n",
        "param0 = [38.9,31.6,410,1126259462.42,0.0,2.2, -1.2, 0.1, 0.]\n",
        "\n",
        "template0 = gen_template(param0)\n",
        "for ifo in ifos:\n",
        "    white_template = template0[ifo].whiten(asd=np.sqrt(psd[ifo]),highpass=20.)\n",
        "\n",
        "    plt.figure(figsize=[15, 3])\n",
        "    plt.plot(white_data[ifo].times, white_data[ifo], label=\"Data\")\n",
        "    plt.plot(white_template.times, white_template, label=\"Template\")\n",
        "\n",
        "    plt.xlim(time_center+.2, time_center+.5)\n",
        "    plt.legend();\n",
        "print(loglikelihood(param0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvZA72ZIIClu"
      },
      "source": [
        "Now let's maximize the likelihood to find the best-fit signal.  We'll use the `minimize()` function provided by scipy using the Powell method, since it's pretty good at dealing with non-smooth functions.  We'll also define a callback function to print likelihood values and plot the model as it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36iWBLPnIClu"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import minimize\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=[15, 6])\n",
        "Neval = 1\n",
        "    \n",
        "lines = {}\n",
        "for ax, ifo in zip(axs, ifos):\n",
        "    hite_template = template0[ifo].whiten(asd=np.sqrt(psd[ifo]),highpass=20.)\n",
        "\n",
        "    ax.plot(white_data[ifo].times, white_data[ifo], label=\"Data\")\n",
        "    lines[ifo], = ax.plot(white_template.times, white_template, label=\"Template\")\n",
        "\n",
        "    ax.set_xlim(time_center+.2, time_center+.5)\n",
        "    ax.legend()\n",
        "\n",
        "def callback(param_i):\n",
        "    global Neval\n",
        "    global line\n",
        "    global fig\n",
        "    \n",
        "    template = gen_template(param_i)\n",
        "    for ifo in ifos:\n",
        "        white_template = template[ifo].whiten(asd=np.sqrt(psd[ifo]),highpass=20.)\n",
        "        lines[ifo].set_ydata(white_template)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(fig)\n",
        "    print(\"Steps\\tlog(likelihood)\")\n",
        "    print('{}\\t{:.3f}'.format(Neval, loglikelihood(param_i)))\n",
        "    \n",
        "    Neval += 1\n",
        "    \n",
        "res = minimize(lambda param: -loglikelihood(param), param0, callback=callback, method='powell')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwHy_0IgIClv"
      },
      "source": [
        "We've now got our best-fit waveform, and it matches the data (although the fitting algorith does fail sometimes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo00W2YqIClv"
      },
      "outputs": [],
      "source": [
        "best_fit = res.x\n",
        "best_fit_template = gen_template(best_fit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqvxOWe5IClw"
      },
      "source": [
        "Now let's subtract it from the data and see how consistent the residuals are with noise. We are using here the [Q-transform](https://en.wikipedia.org/wiki/Constant-Q_transform) to produce a high-resolution time-frequency map of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_bQY6BsIClx"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i, ifo in enumerate(ifos):\n",
        "    subtracted = data[ifo] - best_fit_template[ifo]\n",
        "\n",
        "    # Plot the original data and the subtracted signal data\n",
        "    for d, title in [(data[ifo], 'Original {} Data'.format(ifo)),\n",
        "                 (subtracted, 'Signal Subtracted from {} Data'.format(ifo))]:\n",
        "\n",
        "        qspecgram=d.whiten(asd=np.sqrt(psd[ifo])).q_transform(outseg=(time_center - 1, time_center + 1),\n",
        "                                                     frange=(20, 512))\n",
        "        \n",
        "        plot = qspecgram.plot(figsize=[8, 4],vmin=0,vmax=300)\n",
        "        ax = plot.gca()\n",
        "        ax.set_title(title)\n",
        "        ax.set_xscale('seconds')\n",
        "        ax.set_yscale('log')\n",
        "        ax.set_ylim(20, 500)\n",
        "        ax.set_ylabel('Frequency [Hz]')\n",
        "        ax.grid(True, axis='y', which='both')\n",
        "        ax.colorbar(cmap='viridis', label='Normalized energy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixv4-9cYIClx"
      },
      "source": [
        "# Prior\n",
        "\n",
        "So far we've focused on the likelihood, but equally important to Bayesian inference is our prior, the knowledge of the distribution of model parameters that we have *before* taking any measuments.\n",
        "\n",
        "If we were to sample the likelihood function defined above without specifying any priors, we are implicitly adopting uniform priors for the parameters of the model.  In other words, if we were to sample the same likelihood in a different parameterization, we would implicitly be using a *different* prior for our analysis.\n",
        "\n",
        "While uniform priors for some parameters (e.g., merger time, merger phase, etc.) are justified, the fact that we expect sources to be distributed uniformly in the local universe (to 1st order) needs to be included in our prior, i.e.,\n",
        "\n",
        "$$\n",
        "p(\\alpha, \\delta) \\propto \\cos(\\delta),\n",
        "$$\n",
        "\n",
        "where $\\alpha \\in [0, 2\\pi]$ is the right ascenscion and $\\delta \\in [-\\pi/2, \\pi/2]$ the declination of the source, and\n",
        "\n",
        "$$\n",
        "p(D, \\iota) \\propto D^2\\sin(\\iota)\n",
        "$$\n",
        "\n",
        "where $D$ is the luminosity distance to the source, and $\\iota$ is the inclination angle of the binary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqgHzZBIICly"
      },
      "outputs": [],
      "source": [
        "def logprior(param):\n",
        "    logp = 0\n",
        "    \n",
        "    m1, m2, distance, time, phase, ra, dec, inclination, polarization= param\n",
        "    \n",
        "    for angle in [ra, phase, polarization]:\n",
        "        if angle < 0 or angle > 2*np.pi:\n",
        "            return -np.inf\n",
        "    if distance < 0:\n",
        "        return -np.inf\n",
        "    if inclination < 0 or inclination > np.pi:\n",
        "        return -np.inf\n",
        "    if dec < -np.pi/2 or dec > np.pi/2:\n",
        "        return -np.inf\n",
        "    \n",
        "    logp += np.log(np.cos(dec))\n",
        "    logp += 2*np.log(distance)\n",
        "    logp += np.log(np.sin(inclination))\n",
        "    return logp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwKnjn3LIClz"
      },
      "source": [
        "# Posterior\n",
        "\n",
        "With network likelihood and prior defined we can now take their product to get the posterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNSSH_qJICl0"
      },
      "outputs": [],
      "source": [
        "def logposterior(param):\n",
        "    logpost = logprior(param)\n",
        "    if np.isfinite(logpost):\n",
        "        logpost += loglikelihood(param)\n",
        "    return logpost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndPEGUGRICl0"
      },
      "outputs": [],
      "source": [
        "logposterior(param0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpkoeP7mICl2"
      },
      "source": [
        "We can now maximize the posterior to determine the *maximum a posteriori* (MAP) parameters.  \n",
        "\n",
        "Where the maximum likelihood point was the \"best fit\" in the sense that it found the parameters that produced a model most consistent with the data, the MAP is more of a \"best guess\" in that it balances fitting the data with being consistent with prior expectations for source parameters.\n",
        "\n",
        "However, as the posterior is a density, the MAP **does** depend on the parametrisation we chose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjLTlANfICl2"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 1, figsize=[15, 6])\n",
        "Neval = 1\n",
        "    \n",
        "lines = {}\n",
        "for ax, ifo in zip(axs, ifos):\n",
        "    hite_template = template0[ifo].whiten(asd=np.sqrt(psd[ifo]),highpass=20.)\n",
        "\n",
        "    ax.plot(white_data[ifo].times, white_data[ifo], label=\"Data\")\n",
        "    lines[ifo], = ax.plot(white_template.times, white_template, label=\"Template\")\n",
        "\n",
        "    ax.set_xlim(time_center+.2, time_center+.5)\n",
        "    ax.legend()\n",
        "\n",
        "def callback(param_i):\n",
        "    global Neval\n",
        "    global line\n",
        "    global fig\n",
        "    \n",
        "    template = gen_template(param_i)\n",
        "    for ifo in ifos:\n",
        "        white_template = template[ifo].whiten(asd=np.sqrt(psd[ifo]),highpass=20.)\n",
        "        lines[ifo].set_ydata(white_template)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(fig)\n",
        "    print(\"Steps\\tlog(posterior)\")\n",
        "    print('{}\\t{:.3f}'.format(Neval, logposterior(param_i)))\n",
        "    \n",
        "    Neval += 1\n",
        "    \n",
        "res = minimize(lambda param: -logposterior(param), param0, callback=callback, method='powell')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMsa46ckICl3"
      },
      "outputs": [],
      "source": [
        "best_guess = res.x\n",
        "print(best_guess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cttMtK5HICl3"
      },
      "source": [
        "We can easily take a look at some _slices_ in the parameter space, for instance at the `mass1` slice with all other parameters set the `best_guess` parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q6sFFT-ICl3"
      },
      "outputs": [],
      "source": [
        "masses=np.linspace(25,60,num=200)\n",
        "logl_mass=[]\n",
        "\n",
        "for mass1 in masses:\n",
        "    param_test = best_guess\n",
        "    # m1, m2, distance, time, phase, ra, dec, inclination, polarization = param\n",
        "    param_test[0] = mass1\n",
        "    logl_mass.append(loglikelihood(param_test))\n",
        "    \n",
        "plt.plot(masses,logl_mass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cI1l_qdICl4"
      },
      "source": [
        "**However**, this is just a slice and **not** the marginalised posterior density function for `mass1`. In other to actually compute the marginalised posterior distribution:\n",
        "\n",
        "$$\n",
        "p(m_1|s) = \\int p(\\vec{\\lambda}|s)~d (\\{\\vec{\\lambda}\\}\\setminus \\{m_1\\})\n",
        "$$\n",
        "\n",
        "We need to compute that integral. And one of the most efficient way is to  _sample_ the posterior:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCtj516ZICl5"
      },
      "source": [
        "# Posterior sampling\n",
        "\n",
        "So far we've been generating point estimates for the source parameters, but the whole point of this endeavor was to quantify uncertainties. With our posterior function defined we can now plug into into a Markov chain Monte Carlo sampler in order to draw samples from this probability density function.\n",
        "\n",
        "With a posterior density function defined, you can now use off-the-shelf samplers, see [Samplers, samplers, everywhere...](http://mattpitkin.github.io/samplers-demo/pages/samplers-samplers-everywhere/) to draw samples from the posterior probability density function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "secW9bk8ICl5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "chapter8.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}